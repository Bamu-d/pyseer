#!/usr/bin/env python
'''Python reimplementation of SEER for bacterial GWAS

Copyright 2017 Marco Galardini'''

import contextlib

def get_options():
    import argparse

    description = 'SEER (doi: 10.1038/ncomms12797), reimplemented in python'
    parser = argparse.ArgumentParser(description=description)

    parser.add_argument('kmers',
                        help='Kmers file')
    parser.add_argument('phenotypes',
                        help='Phenotypes file')
    parser.add_argument('distances',
                        help='Strains distance square matrix')

    parser.add_argument('--continuous',
                        action='store_true',
                        default=False,
                        help='Continuous phenotype [Default: binary]')
    parser.add_argument('--min-af',
                        type=float,
                        default=0.01,
                        help='Minimum AF [Default: 0.01]')
    parser.add_argument('--max-af',
                        type=float,
                        default=0.99,
                        help='Maximum AF [Default: 0.99]')
    parser.add_argument('--filter-pvalue',
                        type=float,
                        default=1,
                        help='Prefiltering t-test pvalue threshold [Default: 1]')
    parser.add_argument('--lrt-pvalue',
                        type=float,
                        default=1,
                        help='Likelihood ratio test pvalue threshold [Default: 1]')
    parser.add_argument('--max-dimensions',
                        type=int,
                        default=10,
                        help='Maximum number of dimensions to consider after MDS [Default: 10]')
    parser.add_argument('--covariates',
                        default=None,
                        help='User-defined covariates file (tab-delimited, no header, ' +
                             'first column contains sample names)')
    parser.add_argument('--use-covariates',
                        default=None,
                        nargs='*',
                        help='Covariates to use. Format is "2 3q 4" (q for quantitative)'
                             ' [Default: load covariates but don\'t use them]')
    parser.add_argument('--uncompressed',
                        action='store_true',
                        default=False,
                        help='Uncompressed kmers file [Default: gzipped]')
    parser.add_argument('--cpu',
                        type=int,
                        default=1,
                        help='Processes [Default: 1]')

    return parser.parse_args()


# thanks to Laurent LAPORTE on SO
@contextlib.contextmanager
def set_env(**environ):
    """
    Temporarily set the process environment variables.

    >>> with set_env(PLUGINS_DIR=u'test/plugins'):
    ...   "PLUGINS_DIR" in os.environ
    True

    >>> "PLUGINS_DIR" in os.environ
    False
    """
    old_environ = dict(os.environ)
    os.environ.update(environ)
    try:
        yield
    finally:
        os.environ.clear()
        os.environ.update(old_environ)


# thanks to Francis Song for this function
# source: http://www.nervouscomputer.com/hfs/cmdscale-in-python/
def cmdscale(D):
    """
    Classical multidimensional scaling (MDS)

    Parameters
    ----------
    D : (n, n) array
        Symmetric distance matrix.

    Returns
    -------
    Y : (n, p) array
        Configuration matrix. Each column represents a dimension. Only the
        p dimensions corresponding to positive eigenvalues of B are returned.
        Note that each dimension is only determined up to an overall sign,
        corresponding to a reflection.

    e : (n,) array
        Eigenvalues of B.
    """
    # Number of points
    n = len(D)

    # Centering matrix
    H = np.eye(n) - np.ones((n, n))/n

    # YY^T
    B = -H.dot(D**2).dot(H)/2

    # Diagonalize
    evals, evecs = np.linalg.eigh(B)

    # Sort by eigenvalue in descending order
    idx   = np.argsort(evals)[::-1]
    evals = evals[idx]
    evecs = evecs[:,idx]

    # Compute the coordinates using positive-eigenvalued components only
    w, = np.where(evals > 0)
    L  = np.diag(np.sqrt(evals[w]))
    V  = evecs[:,w]
    Y  = V.dot(L)

    return Y, evals


def iter_kmers(p, m, cov,
               infile, all_strains,
               min_af, max_af,
               filter_pvalue, lrt_pvalue, null_fit):
    for l in infile:
        if not options.uncompressed:
            l = l.decode()
        kmer, strains = l.split()[0], l.rstrip().split()[2:]
        af = float(len(strains)) / len(all_strains)
        # filter by AF
        if af < min_af or af > max_af:
            continue

        d = {x.split(':')[0]: 1
             for x in strains}
        kstrains = sorted(d.keys())
        nkstrains = sorted(all_strains.difference({x.split(':')[0] for x in strains}))
        for x in nkstrains:
            d[x] = 0

        v = p.values
        k = np.array([d[x] for x in p.index
                      if x in d])
        s = m.values
        c = cov.values
        yield (kmer, v, k, s, c, af,
               filter_pvalue, lrt_pvalue, null_fit,
               kstrains, nkstrains)


def binary(kmer, p, k, m, c, af,
           pret, lrtt, null_res,
           kstrains, nkstrains):
    # pre-filtering
    t = np.concatenate((p.reshape(-1, 1), k.reshape(-1, 1)), axis=1).T
    table = [[t[0][(t[0] == 1) & (t[1] == 1)].shape[0],
              t[0][(t[0] == 1) & (t[1] == 0)].shape[0]],
             [t[0][(t[0] == 0) & (t[1] == 1)].shape[0],
              t[0][(t[0] == 0) & (t[1] == 0)].shape[0]]]
    prep = stats.chi2_contingency(table, correction=False)[1]
    if prep > pret:
        return None

    # actual logistic regression
    v = np.concatenate((np.ones(m.shape[0]).reshape(-1, 1),
                        k.reshape(-1, 1),
                        m,
                        c), axis=1)
    mod = smf.Logit(p, v)

    # suppress annoying stdout messages
    old_stdout = sys.stdout
    sys.stdout = open(os.devnull, "w")
    try:
        res = mod.fit(method='newton')
    except np.linalg.linalg.LinAlgError:
        # singular matrix error
        sys.stderr.write('Matrix inversion error with kmer %s\n' % str(kmer))
        return None
    finally:
        sys.stdout.close()
        sys.stdout = old_stdout

    # lrt test for logit
    # lifted from statsmodels code for linear regression
    llf_full = res.llf
    llf_restr = null_res.llf
    df_full = res.df_resid
    df_restr = null_res.df_resid
    lrdf = (df_restr - df_full)
    lrstat = -2*(llf_restr - llf_full)
    lrt_pvalue = stats.chi2.sf(lrstat, lrdf)

    if lrt_pvalue > lrtt:
        return None

    x = '\t'.join([str(x)
                   for x in [kmer,
                             af,
                             prep,
                             lrt_pvalue,
                             res.params[1],
                             res.bse[1],
                             res.params[0]] +
                            list(res.params[2:]) +
                            [','.join(kstrains),
                             ','.join(nkstrains)]])
    return x


def continuous(kmer, p, k, m, c, af,
               pret, lrtt, null_res,
               kstrains, nkstrains):
    # pre-filtering
    prep = stats.ttest_ind(p[k == 1],
                           p[k == 1],
                           equal_var=False)[1]
    if prep > pret:
        return None

    # actual linear regression
    v = np.concatenate((np.ones(m.shape[0]).reshape(-1, 1),
                        k.reshape(-1, 1),
                        m,
                        c), axis=1)
    mod = smf.OLS(p, v)

    # suppress annoying stdout messages
    old_stdout = sys.stdout
    sys.stdout = open(os.devnull, "w")
    try:
        res = mod.fit()
    except np.linalg.linalg.LinAlgError:
        # singular matrix error
        sys.stderr.write('Matrix inversion error with kmer %s\n' % str(kmer))
        return None
    finally:
        sys.stdout.close()
        sys.stdout = old_stdout

    lrt_pvalue = res.compare_lr_test(null_res)[1]
    if lrt_pvalue > lrtt:
        return None

    x = '\t'.join([str(x)
                   for x in [kmer,
                             af,
                             prep,
                             lrt_pvalue,
                             res.params[1],
                             res.bse[1],
                             res.params[0]] +
                            list(res.params[2:]) +
                            [','.join(kstrains),
                             ','.join(nkstrains)]])
    return x

# Fit the null model, regression without k-mer
def fit_null(p, m, cov, continuous):
    v = np.concatenate((p.values.reshape(-1, 1),
                        m.values,
                        cov.values),
                       axis=1)
    df = pd.DataFrame(v,
                      columns=['phenotype'] +
                      ['PC%d'%x for x in range(1, m.shape[1]+1)] +
                      list(cov.columns))
    if continuous:
        null_mod = smf.ols(formula='phenotype ~ ' +
                                   ' + '.join(['PC%d'%x for x in range(1, m.shape[1]+1)]) + ' + ' +
                                   ' + '.join(list(cov.columns)),
                           data=df)
    else:
        null_mod = smf.logit(formula='phenotype ~ ' +
                                     ' + '.join(['PC%d'%x for x in range(1, m.shape[1]+1)]) + ' + ' +
                                     ' + '.join(list(cov.columns)),
                             data=df)

    # suppress annoying stdout messages
    old_stdout = sys.stdout
    sys.stdout = open(os.devnull, "w")
    try:
        if continuous:
            null_res = null_mod.fit()
        else:
            null_res = null_mod.fit(method='newton')

    except np.linalg.linalg.LinAlgError:
        # singular matrix error
        sys.stderr.write('Matrix inversion error with kmer %s\n' % str(k.name))
        return None
    finally:
        sys.stdout.close()
        sys.stdout = old_stdout

    return null_res


if __name__ == "__main__":
    options = get_options()

    import sys
    if options.cpu > 1 and sys.version_info[0] < 3:
        sys.stderr.write('pyseer requires python version 3 or above ' +
                         'unless the number of threads is 1\n')
        sys.exit(1)
    import os

    # avoid numpy taking up more than one thread
    with set_env(MKL_NUM_THREADS='1',
                 NUMEXPR_NUM_THREADS='1',
                 OMP_NUM_THREADS='1'): 
        import sys
        import gzip
        import warnings
        import itertools
        import numpy as np
        import pandas as pd
        from scipy import stats
        from multiprocessing import Pool
        import statsmodels.formula.api as smf

        # silence warnings
        warnings.filterwarnings('ignore')
        #
        
        # reading phenotypes
        p = pd.Series([float(x.rstrip().split()[-1])
                       for x in open(options.phenotypes)],
                      index=[x.split()[0]
                             for x in open(options.phenotypes)])

        # reading genome distances
        m = pd.read_table(options.distances,
                          index_col=0)
        m = m.loc[p.index, p.index]
        # metric MDS scaling
        m = pd.DataFrame(cmdscale(m)[0][:, :options.max_dimensions],
                         index=m.index)
        for i in range(m.shape[1]):
            m[i] = m[i] / max(abs(m[i]))

        all_strains = set(p.index)

        # read covariates
        if options.covariates is not None:
            c = pd.read_table(options.covariates,
                              header=None,
                              index_col=0)
            c.columns = ['covariate%d' % (x+2) for x in range(c.shape[1])]
            c = c.loc[p.index]
            # which covariates to use?
            if options.use_covariates is None:
                cov = pd.DataFrame([])
            else:
                cov = []
                for col in options.use_covariates:
                    cnum = int(col.rstrip('q'))
                    if cnum == 1 or cnum > c.shape[1] + 1:
                        sys.stderr.write('Covariates columns values should be > 1 and lower ' +
                                         'than total number of columns (%d)\n' % (c.shape[1] + 1))
                        sys.exit(1)
                    if col[-1] == 'q':
                        # quantitative
                        cov.append(c['covariate%d' % cnum])
                    else:
                        # categorical, dummy-encode it
                        categories = set(c['covariate%d' % cnum])
                        for i, categ in enumerate(categories):
                            cov.append(pd.Series([1 if x == categ
                                                  else 0
                                                  for x in c['covariate%d' % cnum].values],
                                                 index=c.index,
                                                 name='covariate%d_%d' % (cnum, i)))
                cov = pd.concat(cov, axis=1)
            
        print('\t'.join(['kmer', 'af', 'filter-pvalue',
                         'lrt-pvalue', 'beta', 'beta-std-err',
                         'intercept'] +
                         ['PC%d' % i
                          for i in range(1, options.max_dimensions+1)] +
                         [x
                          for x in cov.columns] +
                         ['k-samples', 'nk-samples']))
        if options.uncompressed:
            infile = open(options.kmers)
        else:
            infile = gzip.open(options.kmers, 'r')

        # multiprocessing setup
        if options.cpu > 1:
            pool = Pool(options.cpu)

        # calculate null regressions once
        null_fit = fit_null(p, m, options.continuous)

        # iterator over each kmer
        # implements maf filtering
        k_iter = iter_kmers(p, m, cov,
                            infile, all_strains,
                            options.min_af, options.max_af,
                            options.filter_pvalue,
                            options.lrt_pvalue, null_fit)

        # actual association test
        if options.cpu > 1:
            # multiprocessing proceeds 1000 MAF-passing kmers per core at a time
            if options.continuous:
                while True:
                    ret = pool.starmap(continuous,
                                       itertools.islice(k_iter,
                                                        options.cpu*1000))
                    if not ret:
                        break
                    for x in ret:
                        if x is None:
                            continue
                        print(x)
            else:
                while True:
                    ret = pool.starmap(binary,
                                       itertools.islice(k_iter,
                                                        options.cpu*1000))
                    if not ret:
                        break
                    for x in ret:
                        if x is None:
                            continue
                        print(x)
        else:
            for data in k_iter:
                if options.continuous:
                    ret = continuous(*data)
                else:
                    ret = binary(*data)
                if ret is None:
                    continue
                print(ret)
